# context_memory.py - Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø³ÙŠØ§Ù‚ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
import json
import time
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from collections import defaultdict
import re

@dataclass
class ConversationContext:
    """Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
    timestamp: str
    user_message: str
    nano_response: str
    emotion_detected: str
    topic_category: str
    cultural_markers: List[str]
    confidence_level: float
    memory_importance: int  # 1-10 scale

@dataclass
class PersonalityProfile:
    """Ù…Ù„Ù Ø§Ù„Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
    name: Optional[str]
    preferred_topics: List[str]
    communication_style: str
    emotional_patterns: Dict[str, int]
    cultural_background: str
    interaction_history: List[str]
    relationship_level: str  # stranger, acquaintance, friend, family

class AdvancedContextMemory:
    """Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø³ÙŠØ§Ù‚ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„Ù†Ø§Ù†Ùˆ"""
    
    def __init__(self, memory_path="nano_memory.json"):
        self.memory_path = memory_path
        self.conversation_history = []
        self.personality_profiles = {}
        self.cultural_patterns = self.initialize_cultural_patterns()
        self.emotion_keywords = self.initialize_emotion_keywords()
        self.topic_classifiers = self.initialize_topic_classifiers()
        
        # Pre-compile keyword sets for faster lookup
        self._compile_pattern_sets()
        self.load_memory()
        
    def initialize_cultural_patterns(self) -> Dict[str, List[str]]:
        """ØªÙ‡ÙŠØ¦Ø© Ø£Ù†Ù…Ø§Ø· Ø«Ù‚Ø§ÙÙŠØ© Ø³Ø¹ÙˆØ¯ÙŠØ©"""
        return {
            "religious": [
                "Ø§Ù„Ù„Ù‡", "Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡", "Ø§Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡", "Ù…Ø§ Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡", "Ø¨Ø¥Ø°Ù† Ø§Ù„Ù„Ù‡",
                "Ø§Ø³ØªØºÙØ± Ø§Ù„Ù„Ù‡", "Ø¨Ø³Ù… Ø§Ù„Ù„Ù‡", "ØµÙ„Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù…", "Ø±Ø­Ù…Ù‡ Ø§Ù„Ù„Ù‡",
                "Ø¬Ø²Ø§Ùƒ Ø§Ù„Ù„Ù‡ Ø®ÙŠØ±", "Ø¨Ø§Ø±Ùƒ Ø§Ù„Ù„Ù‡ ÙÙŠÙƒ", "Ù‡Ø¯Ø§Ùƒ Ø§Ù„Ù„Ù‡", "Ø§Ù„Ù„Ù‡ ÙŠØ¹Ø·ÙŠÙƒ Ø§Ù„Ø¹Ø§ÙÙŠØ©"
            ],
            "greetings": [
                "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…", "Ø£Ù‡Ù„Ø§ ÙˆØ³Ù‡Ù„Ø§", "Ù…Ø±Ø­Ø¨Ø§", "Ø­ÙŠØ§Ùƒ Ø§Ù„Ù„Ù‡", "Ø£Ù‡Ù„ÙŠÙ†",
                "ÙŠØ§ Ù‡Ù„Ø§", "Ù†ÙˆØ±Øª", "ØªØ´Ø±ÙÙ†Ø§", "Ù…Ù†ÙˆØ±", "Ø¹Ø³Ø§Ùƒ Ø¨Ø®ÙŠØ±"
            ],
            "hospitality": [
                "ØªÙØ¶Ù„", "Ø§ØªÙØ¶Ù„", "Ø¨ÙŠØªÙƒ", "Ø£Ù‡Ù„ ÙˆØ³Ù‡Ù„", "ÙƒØ±Ø§Ù…Ø©", "Ø´Ø±ÙØªÙ†Ø§",
                "Ù‚Ù‡ÙˆØ©", "Ø¹Ø´Ø§", "ØºØ¯Ø§", "Ø¶ÙŠÙ", "ÙƒØ±ÙŠÙ…", "Ø¹Ø²ÙŠØ²"
            ],
            "respect": [
                "Ø£Ø³ØªØ§Ø°", "Ø£Ø¨Ùˆ", "Ø£Ù…", "Ø¹Ù…ÙŠ", "Ø®Ø§Ù„ÙŠ", "Ø¹Ù…ØªÙŠ", "Ø®Ø§Ù„ØªÙŠ",
                "Ø­Ø¶Ø±ØªÙƒ", "Ø§Ù„ÙƒØ±ÙŠÙ…", "Ø§Ù„Ù…Ø­ØªØ±Ù…", "Ø§Ù„ÙØ§Ø¶Ù„", "Ø§Ù„Ù…ÙƒØ±Ù…"
            ],
            "emotions": [
                "ÙØ±Ø­Ø§Ù†", "Ù…Ø¨Ø³ÙˆØ·", "Ø³Ø¹ÙŠØ¯", "Ø­Ø²ÙŠÙ†", "Ù…ØªØ¶Ø§ÙŠÙ‚", "Ø®Ø§ÙŠÙ",
                "Ù‚Ù„Ù‚Ø§Ù†", "Ù…Ø±ØªØ§Ø­", "Ù…ØªØ­Ù…Ø³", "Ø²Ø¹Ù„Ø§Ù†", "Ù…Ø³ØªØ§Ù†Ø³"
            ]
        }
    
    def initialize_emotion_keywords(self) -> Dict[str, List[str]]:
        """ØªÙ‡ÙŠØ¦Ø© ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
        return {
            "joy": ["ÙØ±Ø­Ø§Ù†", "Ù…Ø¨Ø³ÙˆØ·", "Ø³Ø¹ÙŠØ¯", "Ù…Ø³ØªØ§Ù†Ø³", "ÙØ±Ø­Ø©", "Ø³Ø¹Ø§Ø¯Ø©", "Ø¨Ù‡Ø¬Ø©"],
            "sadness": ["Ø­Ø²ÙŠÙ†", "Ø²Ø¹Ù„Ø§Ù†", "Ù…ØªØ¶Ø§ÙŠÙ‚", "Ø­Ø²Ù†", "Ø¶ÙŠÙ‚", "ÙƒØ¢Ø¨Ø©", "Ø£Ø³Ù‰"],
            "fear": ["Ø®Ø§ÙŠÙ", "Ù‚Ù„Ù‚Ø§Ù†", "Ù…ØªÙˆØªØ±", "Ø®ÙˆÙ", "Ù‚Ù„Ù‚", "ØªÙˆØªØ±", "Ø±Ø¹Ø¨"],
            "anger": ["Ø²Ø¹Ù„Ø§Ù†", "ØºØ¶Ø¨Ø§Ù†", "Ù…ØªÙ†Ø±ÙØ²", "ØºØ¶Ø¨", "Ø²Ø¹Ù„", "Ø§Ù†ÙØ¹Ø§Ù„", "Ø­Ù†Ù‚"],
            "love": ["Ù…Ø­Ø¨", "Ø£Ø­Ø¨", "Ø¹Ø§Ø´Ù‚", "Ø­Ø¨", "Ø¹Ø´Ù‚", "ØºØ±Ø§Ù…", "Ù‡ÙŠØ§Ù…"],
            "excitement": ["Ù…ØªØ­Ù…Ø³", "Ù…ØªØ´ÙˆÙ‚", "Ø­Ù…Ø§Ø³", "Ø´ÙˆÙ‚", "Ù†Ø´Ø§Ø·", "Ø­ÙŠÙˆÙŠØ©"],
            "calmness": ["Ù‡Ø§Ø¯ÙŠ", "Ù…Ø±ØªØ§Ø­", "Ø³Ø§ÙƒÙ†", "Ù‡Ø¯ÙˆØ¡", "Ø±Ø§Ø­Ø©", "Ø³ÙƒÙŠÙ†Ø©", "Ø·Ù…Ø£Ù†ÙŠÙ†Ø©"],
            "gratitude": ["Ø´ÙƒØ±", "Ø§Ù…ØªÙ†Ø§Ù†", "ØªÙ‚Ø¯ÙŠØ±", "Ø´Ø§ÙƒØ±", "Ù…Ù…ØªÙ†", "Ù…Ù‚Ø¯Ø±"]
        }
    
    def initialize_topic_classifiers(self) -> Dict[str, List[str]]:
        """ØªÙ‡ÙŠØ¦Ø© Ù…ØµÙ†ÙØ§Øª Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹"""
        return {
            "family": ["Ø£Ù‡Ù„", "Ø¹Ø§Ø¦Ù„Ø©", "ÙˆØ§Ù„Ø¯ÙŠÙ†", "Ø§Ø®ÙˆØ§Ù†", "Ø£Ø®ÙˆØ§Øª", "Ø£Ø·ÙØ§Ù„", "Ø¨ÙŠØª", "Ù…Ù†Ø²Ù„"],
            "work": ["Ø´ØºÙ„", "Ø¹Ù…Ù„", "ÙˆØ¸ÙŠÙØ©", "Ù…Ø¯ÙŠØ±", "Ø²Ù…ÙŠÙ„", "Ø±Ø§ØªØ¨", "Ø¯ÙˆØ§Ù…", "Ù…ÙƒØªØ¨"],
            "education": ["Ø¯Ø±Ø§Ø³Ø©", "Ø¬Ø§Ù…Ø¹Ø©", "Ù…Ø¯Ø±Ø³Ø©", "Ø·Ø§Ù„Ø¨", "Ø§Ù…ØªØ­Ø§Ù†", "Ø¯Ø±Ø¬Ø§Øª", "ØªØ¹Ù„ÙŠÙ…"],
            "health": ["ØµØ­Ø©", "Ù…Ø±Ø¶", "Ù…Ø³ØªØ´ÙÙ‰", "Ø¯ÙƒØªÙˆØ±", "Ø¯ÙˆØ§Ø¡", "Ø¹Ù„Ø§Ø¬", "ÙØ­Øµ"],
            "food": ["Ø£ÙƒÙ„", "Ø·Ø¹Ø§Ù…", "Ø·Ø¨Ø®", "Ù…Ø·Ø¹Ù…", "ÙˆØ¬Ø¨Ø©", "Ø¥ÙØ·Ø§Ø±", "ØºØ¯Ø§", "Ø¹Ø´Ø§"],
            "travel": ["Ø³ÙØ±", "Ø±Ø­Ù„Ø©", "Ù…Ø·Ø§Ø±", "ÙÙ†Ø¯Ù‚", "Ø³ÙŠØ§Ø­Ø©", "Ø¥Ø¬Ø§Ø²Ø©", "Ø¨Ù„Ø¯"],
            "technology": ["Ø¬ÙˆØ§Ù„", "ÙƒÙ…Ø¨ÙŠÙˆØªØ±", "Ø¥Ù†ØªØ±Ù†Øª", "ØªÙ‚Ù†ÙŠØ©", "Ø¨Ø±Ù†Ø§Ù…Ø¬", "ØªØ·Ø¨ÙŠÙ‚"],
            "sports": ["Ø±ÙŠØ§Ø¶Ø©", "ÙƒØ±Ø©", "ÙØ±ÙŠÙ‚", "Ù„Ø§Ø¹Ø¨", "Ù…Ø¨Ø§Ø±Ø§Ø©", "Ù†Ø§Ø¯ÙŠ", "ØªÙ…Ø±ÙŠÙ†"],
            "weather": ["Ø·Ù‚Ø³", "Ù…Ø·Ø±", "Ø´Ù…Ø³", "Ø¨Ø±Ø¯", "Ø­Ø±", "ØºÙŠÙˆÙ…", "Ø±ÙŠØ§Ø­"],
            "shopping": ["ØªØ³ÙˆÙ‚", "Ø´Ø±Ø§Ø¡", "Ù…ÙˆÙ„", "Ø³ÙˆÙ‚", "Ø³Ø¹Ø±", "Ø®ØµÙ…", "Ù…ØªØ¬Ø±"]
        }
        
    def _compile_pattern_sets(self):
        """Pre-compile keyword sets for faster pattern matching"""
        # Emotion keyword sets (lowercase)
        self._emotion_sets = {}
        for emotion, keywords in self.emotion_keywords.items():
            self._emotion_sets[emotion] = set(kw.lower() for kw in keywords)
            
        # Topic classifier sets (lowercase)
        self._topic_sets = {}
        for topic, keywords in self.topic_classifiers.items():
            self._topic_sets[topic] = set(kw.lower() for kw in keywords)
            
        # Cultural pattern sets (lowercase)
        self._cultural_sets = {}
        for category, patterns in self.cultural_patterns.items():
            self._cultural_sets[category] = set(p.lower() for p in patterns)
    
    def detect_emotion(self, text: str) -> Tuple[str, float]:
        """ÙƒØ´Ù Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù…Ù† Ø§Ù„Ù†Øµ (Ù…Ø­Ø³Ù‘Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡)"""
        text_lower = text.lower()
        text_words = set(text_lower.split())
        
        emotion_scores = {}
        for emotion, keyword_set in self._emotion_sets.items():
            matches = len(text_words & keyword_set)
            if matches > 0:
                emotion_scores[emotion] = matches
        
        if not emotion_scores:
            return "neutral", 0.5
        
        dominant_emotion = max(emotion_scores, key=emotion_scores.get)
        confidence = min(emotion_scores[dominant_emotion] / len(text_words), 1.0)
        
        return dominant_emotion, confidence
    
    def classify_topic(self, text: str) -> str:
        """ØªØµÙ†ÙŠÙ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ù†Øµ (Ù…Ø­Ø³Ù‘Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡)"""
        text_words = set(text.lower().split())
        
        topic_scores = {}
        for topic, keyword_set in self._topic_sets.items():
            matches = len(text_words & keyword_set)
            if matches > 0:
                topic_scores[topic] = matches
        
        if not topic_scores:
            return "general"
        
        return max(topic_scores, key=topic_scores.get)
    
    def extract_cultural_markers(self, text: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø«Ù‚Ø§ÙÙŠØ© (Ù…Ø­Ø³Ù‘Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡)"""
        text_words = set(text.lower().split())
        markers = []
        
        for category, pattern_set in self._cultural_sets.items():
            matches = text_words & pattern_set
            for match in matches:
                markers.append(f"{category}:{match}")
        
        return markers
    
    def calculate_memory_importance(self, context: ConversationContext) -> int:
        """Ø­Ø³Ø§Ø¨ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        importance = 5  # Base importance
        
        # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø£Ù‡Ù…ÙŠØ© Ù„Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù‚ÙˆÙŠØ©
        if context.emotion_detected in ["joy", "sadness", "fear", "love"]:
            importance += 2
        
        # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø£Ù‡Ù…ÙŠØ© Ù„Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø´Ø®ØµÙŠØ©
        personal_keywords = ["Ø§Ø³Ù…ÙŠ", "Ø£Ù†Ø§", "Ø¨ÙŠØªÙŠ", "Ø¹Ø§Ø¦Ù„ØªÙŠ", "Ø´ØºÙ„ÙŠ"]
        if any(keyword in context.user_message.lower() for keyword in personal_keywords):
            importance += 3
        
        # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø£Ù‡Ù…ÙŠØ© Ù„Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø«Ù‚Ø§ÙÙŠØ©
        if len(context.cultural_markers) > 2:
            importance += 1
        
        # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø£Ù‡Ù…ÙŠØ© Ù„Ù„Ø«Ù‚Ø© Ø§Ù„Ø¹Ø§Ù„ÙŠØ©
        if context.confidence_level > 0.8:
            importance += 1
        
        return min(importance, 10)
    
    def add_conversation_context(self, user_message: str, nano_response: str) -> ConversationContext:
        """Ø¥Ø¶Ø§ÙØ© Ø³ÙŠØ§Ù‚ Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯"""
        emotion, confidence = self.detect_emotion(user_message)
        topic = self.classify_topic(user_message)
        cultural_markers = self.extract_cultural_markers(user_message + " " + nano_response)
        
        context = ConversationContext(
            timestamp=datetime.now().isoformat(),
            user_message=user_message,
            nano_response=nano_response,
            emotion_detected=emotion,
            topic_category=topic,
            cultural_markers=cultural_markers,
            confidence_level=confidence,
            memory_importance=0  # Will be calculated
        )
        
        context.memory_importance = self.calculate_memory_importance(context)
        self.conversation_history.append(context)
        
        # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø¢Ø®Ø± 1000 Ù…Ø­Ø§Ø¯Ø«Ø© ÙÙ‚Ø·
        if len(self.conversation_history) > 1000:
            self.conversation_history = self.conversation_history[-1000:]
        
        return context
    
    def get_relevant_context(self, current_message: str, limit: int = 5) -> List[ConversationContext]:
        """Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø°ÙŠ Ø§Ù„ØµÙ„Ø©"""
        current_emotion, _ = self.detect_emotion(current_message)
        current_topic = self.classify_topic(current_message)
        current_markers = self.extract_cultural_markers(current_message)
        
        # ØªØ³Ø¬ÙŠÙ„ Ù†Ù‚Ø§Ø· Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
        scored_contexts = []
        for context in self.conversation_history[-50:]:  # Ø¢Ø®Ø± 50 Ù…Ø­Ø§Ø¯Ø«Ø©
            score = 0
            
            # Ù†ÙØ³ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
            if context.emotion_detected == current_emotion:
                score += 3
            
            # Ù†ÙØ³ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹
            if context.topic_category == current_topic:
                score += 2
            
            # Ø¹Ù„Ø§Ù…Ø§Øª Ø«Ù‚Ø§ÙÙŠØ© Ù…Ø´ØªØ±ÙƒØ©
            common_markers = set(context.cultural_markers) & set(current_markers)
            score += len(common_markers)
            
            # Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            score += context.memory_importance / 2
            
            # Ø­Ø¯Ø§Ø«Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
            age_hours = (datetime.now() - datetime.fromisoformat(context.timestamp)).total_seconds() / 3600
            if age_hours < 24:
                score += 2
            elif age_hours < 168:  # Ø£Ø³Ø¨ÙˆØ¹
                score += 1
            
            scored_contexts.append((context, score))
        
        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø·
        scored_contexts.sort(key=lambda x: x[1], reverse=True)
        
        return [context for context, score in scored_contexts[:limit]]
    
    def generate_contextual_response_hints(self, user_message: str) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙ„Ù…ÙŠØ­Ø§Øª Ù„Ù„Ø±Ø¯ Ø§Ù„Ø³ÙŠØ§Ù‚ÙŠ"""
        relevant_contexts = self.get_relevant_context(user_message)
        emotion, confidence = self.detect_emotion(user_message)
        topic = self.classify_topic(user_message)
        cultural_markers = self.extract_cultural_markers(user_message)
        
        hints = {
            "detected_emotion": emotion,
            "emotion_confidence": confidence,
            "topic_category": topic,
            "cultural_markers": cultural_markers,
            "relevant_history": [
                {
                    "user_said": ctx.user_message,
                    "nano_responded": ctx.nano_response,
                    "emotion": ctx.emotion_detected,
                    "topic": ctx.topic_category
                }
                for ctx in relevant_contexts
            ],
            "conversation_patterns": self.analyze_conversation_patterns(),
            "suggested_tone": self.suggest_response_tone(emotion, cultural_markers),
            "memory_triggers": self.find_memory_triggers(user_message)
        }
        
        return hints
    
    def analyze_conversation_patterns(self) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
        if len(self.conversation_history) < 5:
            return {"insufficient_data": True}
        
        recent_emotions = [ctx.emotion_detected for ctx in self.conversation_history[-10:]]
        recent_topics = [ctx.topic_category for ctx in self.conversation_history[-10:]]
        
        emotion_frequency = defaultdict(int)
        topic_frequency = defaultdict(int)
        
        for emotion in recent_emotions:
            emotion_frequency[emotion] += 1
        
        for topic in recent_topics:
            topic_frequency[topic] += 1
        
        return {
            "dominant_emotion": max(emotion_frequency, key=emotion_frequency.get) if emotion_frequency else "neutral",
            "frequent_topics": list(topic_frequency.keys()),
            "conversation_mood": self.assess_conversation_mood(recent_emotions),
            "engagement_level": self.calculate_engagement_level()
        }
    
    def suggest_response_tone(self, emotion: str, cultural_markers: List[str]) -> str:
        """Ø§Ù‚ØªØ±Ø§Ø­ Ù†Ø¨Ø±Ø© Ø§Ù„Ø±Ø¯"""
        tone_mapping = {
            "joy": "enthusiastic_supportive",
            "sadness": "empathetic_comforting", 
            "fear": "reassuring_calming",
            "anger": "understanding_diplomatic",
            "love": "warm_appreciative",
            "excitement": "matching_enthusiasm",
            "calmness": "peaceful_gentle",
            "gratitude": "humble_gracious"
        }
        
        base_tone = tone_mapping.get(emotion, "neutral_friendly")
        
        # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†Ø¨Ø±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø«Ù‚Ø§ÙÙŠØ©
        religious_markers = [m for m in cultural_markers if m.startswith("religious:")]
        if religious_markers:
            base_tone += "_respectful"
        
        formal_markers = [m for m in cultural_markers if m.startswith("respect:")]
        if formal_markers:
            base_tone += "_formal"
        
        return base_tone
    
    def find_memory_triggers(self, message: str) -> List[str]:
        """Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø­ÙØ²Ø§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        triggers = []
        message_lower = message.lower()
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø¹Ù† Ù…ÙˆØ§Ø¶ÙŠØ¹ Ù…Ø´Ø§Ø¨Ù‡Ø©
        for context in self.conversation_history[-100:]:
            user_words = set(context.user_message.lower().split())
            message_words = set(message_lower.split())
            
            common_words = user_words & message_words
            if len(common_words) > 2:
                triggers.append(f"similar_to: {context.user_message[:50]}...")
        
        return triggers[:3]  # Ø£Ù‡Ù… 3 Ù…Ø­ÙØ²Ø§Øª
    
    def assess_conversation_mood(self, emotions: List[str]) -> str:
        """ØªÙ‚ÙŠÙŠÙ… Ù…Ø²Ø§Ø¬ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
        positive_emotions = ["joy", "love", "excitement", "gratitude"]
        negative_emotions = ["sadness", "fear", "anger"]
        
        positive_count = sum(1 for e in emotions if e in positive_emotions)
        negative_count = sum(1 for e in emotions if e in negative_emotions)
        
        if positive_count > negative_count * 1.5:
            return "positive"
        elif negative_count > positive_count * 1.5:
            return "negative"
        else:
            return "balanced"
    
    def calculate_engagement_level(self) -> float:
        """Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙØ§Ø¹Ù„"""
        if len(self.conversation_history) < 3:
            return 0.5
        
        recent_contexts = self.conversation_history[-10:]
        
        # Ù‚ÙŠØ§Ø³ Ø·ÙˆÙ„ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
        avg_message_length = sum(len(ctx.user_message.split()) for ctx in recent_contexts) / len(recent_contexts)
        
        # Ù‚ÙŠØ§Ø³ ØªÙ†ÙˆØ¹ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹
        unique_topics = len(set(ctx.topic_category for ctx in recent_contexts))
        
        # Ù‚ÙŠØ§Ø³ Ø§Ù„Ø¹Ù…Ù‚ Ø§Ù„Ø¹Ø§Ø·ÙÙŠ
        emotional_depth = sum(1 for ctx in recent_contexts if ctx.confidence_level > 0.7)
        
        engagement = min((avg_message_length / 10 + unique_topics / 5 + emotional_depth / 10) / 3, 1.0)
        
        return engagement
    
    def save_memory(self):
        """Ø­ÙØ¸ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø¥Ù„Ù‰ Ù…Ù„Ù"""
        memory_data = {
            "conversation_history": [asdict(ctx) for ctx in self.conversation_history[-500:]],  # Ø¢Ø®Ø± 500 Ù…Ø­Ø§Ø¯Ø«Ø©
            "personality_profiles": self.personality_profiles,
            "last_updated": datetime.now().isoformat()
        }
        
        with open(self.memory_path, 'w', encoding='utf-8') as f:
            json.dump(memory_data, f, ensure_ascii=False, indent=2)
    
    def load_memory(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù…Ù† Ù…Ù„Ù"""
        try:
            with open(self.memory_path, 'r', encoding='utf-8') as f:
                memory_data = json.load(f)
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª
            self.conversation_history = [
                ConversationContext(**ctx_data) 
                for ctx_data in memory_data.get("conversation_history", [])
            ]
            
            # ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§Øª Ø§Ù„Ø´Ø®ØµÙŠØ©
            self.personality_profiles = memory_data.get("personality_profiles", {})
            
        except FileNotFoundError:
            self.conversation_history = []
            self.personality_profiles = {}
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """Ø§Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        total_conversations = len(self.conversation_history)
        
        if total_conversations == 0:
            return {"total_conversations": 0, "message": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ù…Ø³Ø¬Ù„Ø© Ø¨Ø¹Ø¯"}
        
        emotion_stats = defaultdict(int)
        topic_stats = defaultdict(int)
        
        for ctx in self.conversation_history:
            emotion_stats[ctx.emotion_detected] += 1
            topic_stats[ctx.topic_category] += 1
        
        return {
            "total_conversations": total_conversations,
            "most_common_emotion": max(emotion_stats, key=emotion_stats.get),
            "most_discussed_topic": max(topic_stats, key=topic_stats.get),
            "average_confidence": sum(ctx.confidence_level for ctx in self.conversation_history) / total_conversations,
            "high_importance_memories": sum(1 for ctx in self.conversation_history if ctx.memory_importance > 7),
            "memory_span_days": (
                datetime.now() - datetime.fromisoformat(self.conversation_history[0].timestamp)
            ).days if self.conversation_history else 0
        }

if __name__ == "__main__":
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù…
    print("ğŸ§  Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø³ÙŠØ§Ù‚ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„Ù†Ø§Ù†Ùˆ")
    
    memory_system = AdvancedContextMemory()
    
    # Ù…Ø­Ø§ÙƒØ§Ø© Ù…Ø­Ø§Ø¯Ø«Ø©
    test_conversations = [
        ("Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…ØŒ ÙƒÙŠÙ Ø§Ù„Ø­Ø§Ù„ØŸ", "ÙˆØ¹Ù„ÙŠÙƒÙ… Ø§Ù„Ø³Ù„Ø§Ù…ØŒ Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡ Ø¨Ø®ÙŠØ± ÙˆØ£Ù†Øª ÙƒÙŠÙÙƒØŸ"),
        ("Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡ØŒ Ø£Ù†Ø§ ÙØ±Ø­Ø§Ù† Ø§Ù„ÙŠÙˆÙ… Ù„Ø£Ù† Ø­ØµÙ„Øª Ø¹Ù„Ù‰ ÙˆØ¸ÙŠÙØ© Ø¬Ø¯ÙŠØ¯Ø©", "Ù…Ø¨Ø±ÙˆÙƒ Ø¹Ù„ÙŠÙƒ! Ø§Ù„Ù„Ù‡ ÙŠØ¨Ø§Ø±Ùƒ Ù„Ùƒ ÙÙŠ Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©"),
        ("Ø£Ø´ÙƒØ±ÙƒØŒ Ø¨Ø³ Ù‚Ù„Ù‚Ø§Ù† Ø´ÙˆÙŠ Ù…Ù† Ø§Ù„ØªØ­Ø¯ÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯", "Ù‡Ø°Ø§ Ø·Ø¨ÙŠØ¹ÙŠØŒ Ø¨Ø¥Ø°Ù† Ø§Ù„Ù„Ù‡ ØªØªØ£Ù‚Ù„Ù… Ø¨Ø³Ø±Ø¹Ø© ÙˆØªÙ†Ø¬Ø­"),
        ("ÙƒÙŠÙ Ø£ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø¶ØºØ· Ø§Ù„Ø¹Ù…Ù„ØŸ", "Ø§Ù„Ù…Ù‡Ù… ØªÙ†Ø¸Ù… ÙˆÙ‚ØªÙƒ ÙˆØªØ§Ø®Ø° Ø±Ø§Ø­Ø© Ø¨ÙŠÙ† Ø§Ù„ÙØªØ±Ø§Øª")
    ]
    
    for user_msg, nano_resp in test_conversations:
        context = memory_system.add_conversation_context(user_msg, nano_resp)
        print(f"\nğŸ“ Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©:")
        print(f"Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {user_msg}")
        print(f"Ù†Ø§Ù†Ùˆ: {nano_resp}")
        print(f"Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: {context.emotion_detected}")
        print(f"Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹: {context.topic_category}")
        print(f"Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {context.memory_importance}/10")
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    stats = memory_system.get_memory_stats()
    print(f"\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©:")
    for key, value in stats.items():
        print(f"{key}: {value}")
    
    # Ø­ÙØ¸ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
    memory_system.save_memory()
    print("\nğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø¨Ù†Ø¬Ø§Ø­!")